{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "example_3.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LODx4FOZL7hm",
        "outputId": "8bde6f3c-2643-40b1-acfd-dd356f32c585"
      },
      "source": [
        "!pip install git+https://github.com/Flofega/NNucleate.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/Flofega/NNucleate.git\n",
            "  Cloning https://github.com/Flofega/NNucleate.git to /tmp/pip-req-build-it45fd2b\n",
            "  Running command git clone -q https://github.com/Flofega/NNucleate.git /tmp/pip-req-build-it45fd2b\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from NNucleate==0.1) (1.4.1)\n",
            "Collecting mdtraj\n",
            "  Downloading mdtraj-1.9.6-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (6.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.2 MB 4.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from NNucleate==0.1) (1.19.5)\n",
            "Collecting MDAnalysis\n",
            "  Downloading MDAnalysis-2.0.0.tar.gz (3.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.4 MB 58.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from NNucleate==0.1) (0.29.24)\n",
            "Collecting biopython>=1.71\n",
            "  Downloading biopython-1.79-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (2.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3 MB 40.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: networkx>=1.0 in /usr/local/lib/python3.7/dist-packages (from MDAnalysis->NNucleate==0.1) (2.6.3)\n",
            "Collecting GridDataFormats>=0.4.0\n",
            "  Downloading GridDataFormats-0.5.0-py2.py3-none-any.whl (2.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.0 MB 72.9 MB/s \n",
            "\u001b[?25hCollecting mmtf-python>=1.0.0\n",
            "  Downloading mmtf_python-1.1.2-py2.py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: joblib>=0.12 in /usr/local/lib/python3.7/dist-packages (from MDAnalysis->NNucleate==0.1) (1.0.1)\n",
            "Requirement already satisfied: matplotlib>=1.5.1 in /usr/local/lib/python3.7/dist-packages (from MDAnalysis->NNucleate==0.1) (3.2.2)\n",
            "Requirement already satisfied: tqdm>=4.43.0 in /usr/local/lib/python3.7/dist-packages (from MDAnalysis->NNucleate==0.1) (4.62.2)\n",
            "Collecting threadpoolctl\n",
            "  Downloading threadpoolctl-2.2.0-py3-none-any.whl (12 kB)\n",
            "Collecting gsd>=1.4.0\n",
            "  Downloading gsd-2.4.2-cp37-cp37m-manylinux2010_x86_64.whl (334 kB)\n",
            "\u001b[K     |████████████████████████████████| 334 kB 69.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from GridDataFormats>=0.4.0->MDAnalysis->NNucleate==0.1) (1.15.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.5.1->MDAnalysis->NNucleate==0.1) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.5.1->MDAnalysis->NNucleate==0.1) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.5.1->MDAnalysis->NNucleate==0.1) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.5.1->MDAnalysis->NNucleate==0.1) (2.4.7)\n",
            "Requirement already satisfied: msgpack>=0.5.6 in /usr/local/lib/python3.7/dist-packages (from mmtf-python>=1.0.0->MDAnalysis->NNucleate==0.1) (1.0.2)\n",
            "Requirement already satisfied: astunparse in /usr/local/lib/python3.7/dist-packages (from mdtraj->NNucleate==0.1) (1.6.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse->mdtraj->NNucleate==0.1) (0.37.0)\n",
            "Building wheels for collected packages: NNucleate, MDAnalysis\n",
            "  Building wheel for NNucleate (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for NNucleate: filename=NNucleate-0.1-py3-none-any.whl size=10986 sha256=5d463813dde3f39fd41a73efa806f62833858b8a2878cb8b375c3fdc85472191\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-6xovyack/wheels/44/6d/1b/ae654aec4ee2888c1de63303dd425d120ea950760fd6f9c48a\n",
            "  Building wheel for MDAnalysis (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for MDAnalysis: filename=MDAnalysis-2.0.0-cp37-cp37m-linux_x86_64.whl size=4486237 sha256=5e85c50481f2d6cfbba90e1d3a24b3f68574eacf0024caba4718535165610b92\n",
            "  Stored in directory: /root/.cache/pip/wheels/e9/38/a1/b52afa08dcd5300512ec92a8878f48c3460f92a72745e057c1\n",
            "Successfully built NNucleate MDAnalysis\n",
            "Installing collected packages: threadpoolctl, mmtf-python, gsd, GridDataFormats, biopython, mdtraj, MDAnalysis, NNucleate\n",
            "Successfully installed GridDataFormats-0.5.0 MDAnalysis-2.0.0 NNucleate-0.1 biopython-1.79 gsd-2.4.2 mdtraj-1.9.6 mmtf-python-1.1.2 threadpoolctl-2.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vN3lRgzP4bFv",
        "outputId": "3aa5796b-0284-4648-9bd6-ccc0e8cc44fc"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Crov4k_5raJ"
      },
      "source": [
        "path = \"drive/MyDrive/Permutational_Invariance/\""
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hb68tY1x4zOY",
        "outputId": "1f03b947-3d7e-4dae-daa1-d79871cb05e3"
      },
      "source": [
        "from NNucleate.trainig import test, train_perm, NNCV, CVTrajectory\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from time import time\n",
        "import numpy as np\n",
        "\n",
        "# Train multiple models with train perm and plot performance against n_trans\n",
        "# Get a cpu or GPU for training\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using {} device\".format(device))\n",
        "\n",
        "\n",
        "ns = [1, 2, 5]\n",
        "\n",
        "traj_path = path + \"trajectories/dump.3Dcolloid.13.xyz\"\n",
        "cv_path = path + \"trajectories/cn.13.dat\"\n",
        "top_path = path + \"trajectories/reference_13.pdb\"\n",
        "val_path = path + \"even_shuffled_6k.xtc\"\n",
        "val_cv_path = path + \"even_shuffled_6k_cv.dat\"\n",
        "\n",
        "ds = CVTrajectory(cv_path, traj_path, top_path, 3, 92.83)\n",
        "ds_val = CVTrajectory(val_cv_path, val_path, top_path, 1, 92.83)\n",
        "train_set, test_set = torch.utils.data.random_split(ds, [int(len(ds)*0.8)+1, int(len(ds)*0.2)])\n",
        "\n",
        "train_dataloader = DataLoader(train_set, batch_size=64, shuffle=True)\n",
        "test_dataloader = DataLoader(test_set, batch_size=64, shuffle=True)\n",
        "val_loader = DataLoader(ds_val, batch_size=64, shuffle=True)\n",
        "\n",
        "epochs = 20\n",
        "learning_rate = 1e-4\n",
        "loss_fn = nn.MSELoss()\n",
        "n_at = 421\n",
        "\n",
        "cost = []\n",
        "performance = []\n",
        "trainings = []\n",
        "tests = []\n",
        "vals = []\n",
        "\n",
        "for n in ns:\n",
        "    t1 = time()\n",
        "    model = NNCV(n_at*3, 512, 256, 128).to(device)    \n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    #scheduler = ExponentialLR(optimizer, gamma=0.9)\n",
        "    train_errors = []\n",
        "    test_errors = []\n",
        "    for t in range(epochs):\n",
        "        print(f\"Epoch {t+1}\\n ------------------------------\")\n",
        "        tr = train_perm(train_dataloader, model, loss_fn, optimizer, n, device, 50000)\n",
        "        train_errors.append(tr)\n",
        "        #scheduler.step()\n",
        "        te = test(test_dataloader, model, loss_fn, device)\n",
        "        test_errors.append(te)\n",
        "\n",
        "    t2 = time() - t1\n",
        "    cost.append(t2)\n",
        "    trainings.append(train_errors[-1])\n",
        "    tests.append(test_errors[-1])\n",
        "    print(\"---Validation---\")\n",
        "    val = test(val_loader, model, loss_fn, device)\n",
        "    performance.append(val)\n",
        "\n",
        "    print(\" n = %d Done!\" % n)\n",
        "\n",
        "print(\"--- cost ---\")\n",
        "print(cost)\n",
        "print(\"--- performance ---\")\n",
        "print(performance)\n",
        "print(\"--- trainings ---\")\n",
        "print(trainings)\n",
        "print(\"--- test ---\")\n",
        "print(tests)\n",
        "\n",
        "cost = np.array(cost)/3600\n",
        "\n",
        "fig, ax1 = plt.subplots()\n",
        "\n",
        "ax1.plot(ns, trainings, label=\"Train Error\")\n",
        "ax1.plot(ns, tests, label=\"Test Error\")\n",
        "ax1.plot(ns, performance, label=\"Val. Error\")\n",
        "ax1.legend()\n",
        "ax1.set_xlabel(\"Number of Permutations\")\n",
        "ax1.set_ylabel(\"RMSE\")\n",
        "ax1.tick_params(axis=\"y\")\n",
        "\n",
        "ax2 = ax1.twinx()\n",
        "color = 'tab:purple'\n",
        "ax2.set_ylabel(\"GPU hours\", color=color)\n",
        "ax2.plot(ns, cost, color=color, linestyle=\"dashed\")\n",
        "ax2.tick_params(axis=\"y\", labelcolor=color)\n",
        "fig.tight_layout()\n",
        "plt.savefig(\"comp_graph.png\", dpi=500)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/mdtraj/formats/pdb/pdbfile.py:194: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  particle_density = traj.top.n_atoms / traj.unitcell_volumes[0]\n",
            "/usr/local/lib/python3.7/dist-packages/mdtraj/formats/pdb/pdbfile.py:198: UserWarning: Unlikely unit cell vectors detected in PDB file likely resulting from a dummy CRYST1 record. Discarding unit cell vectors.\n",
            "  'cell vectors.', category=UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            " ------------------------------\n",
            "loss: 158.239243 [    0/ 8001]\n",
            "Avg. Test loss: 59.824761 \n",
            "\n",
            "Epoch 2\n",
            " ------------------------------\n",
            "loss: 100.098351 [    0/ 8001]\n",
            "Avg. Test loss: 56.723105 \n",
            "\n",
            "Epoch 3\n",
            " ------------------------------\n",
            "loss: 121.184067 [    0/ 8001]\n",
            "Avg. Test loss: 44.667684 \n",
            "\n",
            "Epoch 4\n",
            " ------------------------------\n",
            "loss: 60.197414 [    0/ 8001]\n",
            "Avg. Test loss: 36.613376 \n",
            "\n",
            "Epoch 5\n",
            " ------------------------------\n",
            "loss: 35.331001 [    0/ 8001]\n",
            "Avg. Test loss: 31.372870 \n",
            "\n",
            "Epoch 6\n",
            " ------------------------------\n",
            "loss: 70.368088 [    0/ 8001]\n",
            "Avg. Test loss: 26.150815 \n",
            "\n",
            "Epoch 7\n",
            " ------------------------------\n",
            "loss: 70.583069 [    0/ 8001]\n",
            "Avg. Test loss: 22.384462 \n",
            "\n",
            "Epoch 8\n",
            " ------------------------------\n",
            "loss: 24.916950 [    0/ 8001]\n",
            "Avg. Test loss: 19.872624 \n",
            "\n",
            "Epoch 9\n",
            " ------------------------------\n",
            "loss: 43.394279 [    0/ 8001]\n",
            "Avg. Test loss: 16.647719 \n",
            "\n",
            "Epoch 10\n",
            " ------------------------------\n",
            "loss: 49.528053 [    0/ 8001]\n",
            "Avg. Test loss: 14.958069 \n",
            "\n",
            "Epoch 11\n",
            " ------------------------------\n",
            "loss: 25.404486 [    0/ 8001]\n",
            "Avg. Test loss: 12.945521 \n",
            "\n",
            "Epoch 12\n",
            " ------------------------------\n",
            "loss: 31.629921 [    0/ 8001]\n",
            "Avg. Test loss: 11.922622 \n",
            "\n",
            "Epoch 13\n",
            " ------------------------------\n",
            "loss: 30.187742 [    0/ 8001]\n",
            "Avg. Test loss: 10.429533 \n",
            "\n",
            "Epoch 14\n",
            " ------------------------------\n",
            "loss: 28.985489 [    0/ 8001]\n",
            "Avg. Test loss: 8.989370 \n",
            "\n",
            "Epoch 15\n",
            " ------------------------------\n",
            "loss: 25.012247 [    0/ 8001]\n",
            "Avg. Test loss: 8.071662 \n",
            "\n",
            "Epoch 16\n",
            " ------------------------------\n",
            "loss: 18.227772 [    0/ 8001]\n",
            "Avg. Test loss: 6.773126 \n",
            "\n",
            "Epoch 17\n",
            " ------------------------------\n",
            "loss: 20.405914 [    0/ 8001]\n",
            "Avg. Test loss: 5.995516 \n",
            "\n",
            "Epoch 18\n",
            " ------------------------------\n",
            "loss: 19.988674 [    0/ 8001]\n",
            "Avg. Test loss: 4.961263 \n",
            "\n",
            "Epoch 19\n",
            " ------------------------------\n",
            "loss: 19.691498 [    0/ 8001]\n",
            "Avg. Test loss: 4.624306 \n",
            "\n",
            "Epoch 20\n",
            " ------------------------------\n",
            "loss: 20.504574 [    0/ 8001]\n",
            "Avg. Test loss: 3.580240 \n",
            "\n",
            "---Validation---\n",
            "Avg. Test loss: 18.476030 \n",
            "\n",
            " n = 1 Done!\n",
            "Epoch 1\n",
            " ------------------------------\n",
            "loss: 183.484375 [    0/ 8001]\n",
            "Avg. Test loss: 59.567904 \n",
            "\n",
            "Epoch 2\n",
            " ------------------------------\n",
            "loss: 73.474182 [    0/ 8001]\n",
            "Avg. Test loss: 53.099493 \n",
            "\n",
            "Epoch 3\n",
            " ------------------------------\n",
            "loss: 71.265457 [    0/ 8001]\n",
            "Avg. Test loss: 40.612697 \n",
            "\n",
            "Epoch 4\n",
            " ------------------------------\n",
            "loss: 66.097519 [    0/ 8001]\n",
            "Avg. Test loss: 32.574517 \n",
            "\n",
            "Epoch 5\n",
            " ------------------------------\n",
            "loss: 60.542854 [    0/ 8001]\n",
            "Avg. Test loss: 28.107076 \n",
            "\n",
            "Epoch 6\n",
            " ------------------------------\n",
            "loss: 40.736259 [    0/ 8001]\n",
            "Avg. Test loss: 23.447750 \n",
            "\n",
            "Epoch 7\n",
            " ------------------------------\n",
            "loss: 39.080025 [    0/ 8001]\n",
            "Avg. Test loss: 20.129390 \n",
            "\n",
            "Epoch 8\n",
            " ------------------------------\n",
            "loss: 21.846455 [    0/ 8001]\n",
            "Avg. Test loss: 16.499893 \n",
            "\n",
            "Epoch 9\n",
            " ------------------------------\n",
            "loss: 27.719240 [    0/ 8001]\n",
            "Avg. Test loss: 14.287796 \n",
            "\n",
            "Epoch 10\n",
            " ------------------------------\n",
            "loss: 20.624172 [    0/ 8001]\n",
            "Avg. Test loss: 12.980096 \n",
            "\n",
            "Epoch 11\n",
            " ------------------------------\n",
            "loss: 19.255865 [    0/ 8001]\n",
            "Avg. Test loss: 10.579678 \n",
            "\n",
            "Epoch 12\n",
            " ------------------------------\n",
            "loss: 25.162830 [    0/ 8001]\n",
            "Avg. Test loss: 9.443391 \n",
            "\n",
            "Epoch 13\n",
            " ------------------------------\n",
            "loss: 31.122705 [    0/ 8001]\n",
            "Avg. Test loss: 7.970632 \n",
            "\n",
            "Epoch 14\n",
            " ------------------------------\n",
            "loss: 21.611567 [    0/ 8001]\n",
            "Avg. Test loss: 7.145607 \n",
            "\n",
            "Epoch 15\n",
            " ------------------------------\n",
            "loss: 16.005154 [    0/ 8001]\n",
            "Avg. Test loss: 5.971322 \n",
            "\n",
            "Epoch 16\n",
            " ------------------------------\n",
            "loss: 18.041143 [    0/ 8001]\n",
            "Avg. Test loss: 5.156094 \n",
            "\n",
            "Epoch 17\n",
            " ------------------------------\n",
            "loss: 18.471428 [    0/ 8001]\n",
            "Avg. Test loss: 4.508261 \n",
            "\n",
            "Epoch 18\n",
            " ------------------------------\n",
            "loss: 20.772099 [    0/ 8001]\n",
            "Avg. Test loss: 3.826986 \n",
            "\n",
            "Epoch 19\n",
            " ------------------------------\n",
            "loss: 5.924827 [    0/ 8001]\n",
            "Avg. Test loss: 3.270168 \n",
            "\n",
            "Epoch 20\n",
            " ------------------------------\n",
            "loss: 11.348419 [    0/ 8001]\n",
            "Avg. Test loss: 2.550462 \n",
            "\n",
            "---Validation---\n",
            "Avg. Test loss: 14.855601 \n",
            "\n",
            " n = 2 Done!\n",
            "Epoch 1\n",
            " ------------------------------\n",
            "loss: 101.773666 [    0/ 8001]\n",
            "Avg. Test loss: 59.174505 \n",
            "\n",
            "Epoch 2\n",
            " ------------------------------\n",
            "loss: 77.169823 [    0/ 8001]\n",
            "Avg. Test loss: 52.756829 \n",
            "\n",
            "Epoch 3\n",
            " ------------------------------\n",
            "loss: 74.954788 [    0/ 8001]\n",
            "Avg. Test loss: 41.143081 \n",
            "\n",
            "Epoch 4\n",
            " ------------------------------\n",
            "loss: 44.948532 [    0/ 8001]\n",
            "Avg. Test loss: 34.452585 \n",
            "\n",
            "Epoch 5\n",
            " ------------------------------\n",
            "loss: 38.734837 [    0/ 8001]\n",
            "Avg. Test loss: 28.554051 \n",
            "\n",
            "Epoch 6\n",
            " ------------------------------\n",
            "loss: 50.163170 [    0/ 8001]\n",
            "Avg. Test loss: 24.550821 \n",
            "\n",
            "Epoch 7\n",
            " ------------------------------\n",
            "loss: 26.767345 [    0/ 8001]\n",
            "Avg. Test loss: 21.457081 \n",
            "\n",
            "Epoch 8\n",
            " ------------------------------\n",
            "loss: 28.080618 [    0/ 8001]\n",
            "Avg. Test loss: 18.351282 \n",
            "\n",
            "Epoch 9\n",
            " ------------------------------\n",
            "loss: 20.919931 [    0/ 8001]\n",
            "Avg. Test loss: 15.837651 \n",
            "\n",
            "Epoch 10\n",
            " ------------------------------\n",
            "loss: 19.784906 [    0/ 8001]\n",
            "Avg. Test loss: 13.878798 \n",
            "\n",
            "Epoch 11\n",
            " ------------------------------\n",
            "loss: 8.954495 [    0/ 8001]\n",
            "Avg. Test loss: 11.819193 \n",
            "\n",
            "Epoch 12\n",
            " ------------------------------\n",
            "loss: 19.784548 [    0/ 8001]\n",
            "Avg. Test loss: 10.271447 \n",
            "\n",
            "Epoch 13\n",
            " ------------------------------\n",
            "loss: 16.892248 [    0/ 8001]\n",
            "Avg. Test loss: 8.943909 \n",
            "\n",
            "Epoch 14\n",
            " ------------------------------\n",
            "loss: 21.098288 [    0/ 8001]\n",
            "Avg. Test loss: 7.977344 \n",
            "\n",
            "Epoch 15\n",
            " ------------------------------\n",
            "loss: 13.469740 [    0/ 8001]\n",
            "Avg. Test loss: 6.942970 \n",
            "\n",
            "Epoch 16\n",
            " ------------------------------\n",
            "loss: 10.633298 [    0/ 8001]\n",
            "Avg. Test loss: 5.990875 \n",
            "\n",
            "Epoch 17\n",
            " ------------------------------\n",
            "loss: 11.289780 [    0/ 8001]\n",
            "Avg. Test loss: 5.324054 \n",
            "\n",
            "Epoch 18\n",
            " ------------------------------\n",
            "loss: 9.800430 [    0/ 8001]\n",
            "Avg. Test loss: 4.857868 \n",
            "\n",
            "Epoch 19\n",
            " ------------------------------\n",
            "loss: 9.440725 [    0/ 8001]\n",
            "Avg. Test loss: 4.211443 \n",
            "\n",
            "Epoch 20\n",
            " ------------------------------\n",
            "loss: 19.596981 [    0/ 8001]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cM39KuL14158"
      },
      "source": [
        ""
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oEUVKcQq46cU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}